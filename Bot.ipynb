{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by [Gameli Ladzekpo](mailto:gameli.Ladzekpo@gmail.com) (Twitter/IG: @gamladz)\n",
    "\n",
    "For [AI Core](theaicore.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports \n",
    "\n",
    "import json \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from time import sleep, time\n",
    "import random\n",
    "import re\n",
    "import subprocess, os\n",
    "import urllib.request\n",
    "import sys\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from selenium import webdriver \n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up AWS functions\n",
    "s3 = boto3.resource(\"s3\").Bucket(\"ikea-dataset\")\n",
    "json.load_s3 = lambda f: json.load(s3.Object(key=f).get()[\"Body\"])\n",
    "json.dump_s3 = lambda obj, f: s3.Object(key=f).put(Body=json.dumps(obj))\n",
    "client = boto3.client('s3', region_name='us-east-2')\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# json.dump_s3(data, \"key\")  saves json to s3://bucket/key\n",
    "# data = json.load_s3(\"key\")  read json from s3://bucket/key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_chrome function\n",
    "def open_chrome(port=9220, on_mac=True):\n",
    "    my_env = os.environ.copy()\n",
    "    if on_mac:\n",
    "        subprocess.Popen(['open', '-a', \"Google Chrome\", '--args', f'--remote-debugging-port={port}', 'http://www.example.com'], env=my_env)\n",
    "    else:\n",
    "        subprocess.Popen(f'google-chrome --remote-debugging-port={port} --user-data-dir=bots'.split(), env=my_env)\n",
    "\n",
    "class Bot():\n",
    "    def __init__(self, port_no = 9220, headless = False, verbose = False):\n",
    "        print('initialising bot')\n",
    "\n",
    "        open_chrome()\n",
    "\n",
    "        options = Options()\n",
    "        options.add_argument(\"--no-sandbox\")\t# without this, the chrome webdriver can't start (SECURITY RISK)\n",
    "        options.add_experimental_option(f\"debuggerAddress\", f\"127.0.0.1:{port_no}\")\t# attach to the same port that you're running chrome on\n",
    "        if headless:\n",
    "            options.add_argument(\"--headless\") # headless option allows scraper to run in the background\n",
    "        #options.add_argument(\"--window-size=1920x1080\")\n",
    "        self.driver = webdriver.Chrome('chrome_driver/chromedriver')\t\t\t# create webdriver\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def click_btn(self, text):\n",
    "        if self.verbose: print(f'clicking {text} btn')\n",
    "        element_types = ['button', 'div', 'input', 'a', 'label']\n",
    "        \n",
    "        for element_type in element_types:\n",
    "            btns = self.driver.find_elements_by_xpath(f'//{element_type}')\n",
    "            # for btn in btns:\n",
    "            #   print(btn.text)\n",
    "\n",
    "            # SEARCH BY TEXT\n",
    "            try:\n",
    "                btn = [b for b in btns if b.text.lower() == text.lower()][0]\n",
    "                btn.click()\n",
    "                return\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "            # SEARCH BY VALUE ATTRIBUTE IF NOT YET FOUND\n",
    "            try:\n",
    "                btn = self.driver.find_elements_by_xpath(f'//{element_type}[@value=\"{text}\"]')[0]\n",
    "                btn.click()\n",
    "                return\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        raise ValueError(f'button containing \"{text}\" not found')\n",
    "\n",
    "    def _search(self, query, _type='search', placeholder=None):\n",
    "        sleep(1)\n",
    "        s = self.driver.find_elements_by_xpath(f'//input[@type=\"{_type}\"]')\n",
    "        print(s)\n",
    "        if placeholder:\n",
    "            s = [i for i in s if i.get_attribute('placeholder').lower() == placeholder.lower()][0]\n",
    "        else:\n",
    "            s = s[0]\n",
    "        s.send_keys(query) \n",
    "\n",
    "    def toggle_verbose(self):\n",
    "        self.verbose = not self.verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "initialising bot\n",
      "found 202) results for search \"plant pots\" \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_dict' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dac4168471db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# Wrte dict to local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mtest_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_json.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dict' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    bot = Bot()\n",
    "    \n",
    "    data_dict = {\n",
    "        \n",
    "    }\n",
    "\n",
    "    searches = {\n",
    "        \"plant pots\":[], \n",
    "        \"bin\":[],\n",
    "        \"cookware\":[],\n",
    "        \"wardrobes\":[], \n",
    "        \"tables\":[],\n",
    "        \"cabinets\":[],\n",
    "        \"clothing racks\":[],\n",
    "        \"chair\":[]\n",
    "    }\n",
    "    \n",
    "    for search in searches:\n",
    "        bot.driver.get(f'https://www.ikea.com/gb/en/search/products/?q={search}')\n",
    "        data_dict[search] = {}\n",
    "\n",
    "        # Get full grid by trying to scroll and press show more button\n",
    "        while True:\n",
    "            try:\n",
    "                bot.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(5)\n",
    "                show_more_button = bot.driver.find_elements_by_xpath('//*[@class=\"show-more__button button button--secondary button--small\"]')[0]\n",
    "                show_more_button.click()\n",
    "            except IndexError:\n",
    "                break\n",
    "\n",
    "\n",
    "        # Go into the main grid and find the link for each result\n",
    "        results = bot.driver.find_elements_by_xpath('//*[@id=\"search-results\"]/div/a')  \n",
    "        print (f'found {len(results)}) results for search \"{search}\" ')\n",
    "\n",
    "\n",
    "        results = [r.get_attribute('href') for r in results]\n",
    "\n",
    "        for i, result in enumerate(results):\n",
    "\n",
    "            # Skip promotional links, adverts or non-product links in grid\n",
    "            if '/p/' not in result:\n",
    "                continue \n",
    "\n",
    "            bot.driver.get(result)\n",
    "            result = result.split('/')[-2]\n",
    "\n",
    "            # Set up dict for each products result\n",
    "            results_dict = {\n",
    "                \"id\": [],\n",
    "                \"prod_name\": [],\n",
    "                \"prod_price\": [],\n",
    "                \"prod_desc\": [],\n",
    "                \"prod_dimensions\": [],\n",
    "                \"packaging\": [],\n",
    "                \"prod_details\": [],\n",
    "                \"sustainability\": [],\n",
    "                \"images\":[],\n",
    "                \"materials\":[]\n",
    "            }\n",
    "            \n",
    "\n",
    "            results_dict['id'] = hash(result)\n",
    "\n",
    "\n",
    "            # Extract Product Description\n",
    "            prod_name = bot.driver.find_element_by_xpath('//*[@class=\"range-revamp-header-section__title--big\"]')\n",
    "            prod_name = prod_name.get_attribute('innerHTML')              \n",
    "            results_dict['prod_name'] = prod_name\n",
    "                        \n",
    "\n",
    "            prod_price = bot.driver.find_element_by_xpath('//*[@class=\"range-revamp-price__integer\"]')\n",
    "            prod_price = prod_price.get_attribute('innerHTML')\n",
    "            results_dict['prod_price'] = prod_price\n",
    "\n",
    "\n",
    "            prod_desc = bot.driver.find_element_by_xpath('//*[@class=\"range-revamp-header-section__description-text\"]')\n",
    "            prod_desc = prod_desc.get_attribute('innerHTML')\n",
    "            results_dict['prod_desc'] = prod_desc\n",
    "\n",
    "\n",
    "            os.makedirs(f'data/{search}/{result}', exist_ok=True)\n",
    "\n",
    "            # First get the image - product dimensions image\n",
    "            prod_dims_images = bot.driver.find_elements_by_xpath('//*[@class=\"range-revamp-product-dimensions-content__images\"]//img')\n",
    "            prod_dims_images = [i.get_attribute('src') for i in prod_dims_images]\n",
    "\n",
    "            for image in prod_dims_images:\n",
    "                # Loop through each image and save to disk\n",
    "\n",
    "                for idx, img_url in enumerate(images):\n",
    "\n",
    "                    # Create filename for each with ID and get the file extension\n",
    "                    filename = f'dims-{result}-{idx}'\n",
    "                    file_ext = img_url.split('.')[-1] \n",
    "                    file_ext = file_ext[ 0 : 3 ]\n",
    "                    # Write file locally\n",
    "                    filepath = f'data/{search}/{result}/{filename}.{file_ext}'\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(img_url, filepath)\n",
    "                    except ConnectionResetError:\n",
    "                        print ('Connection Error')\n",
    "                    else:\n",
    "                        img_data = requests.get(img_url).content\n",
    "                        with open(filepath, 'wb') as handler:\n",
    "                            handler.write(img_data)                         \n",
    "                    finally:\n",
    "                        pass\n",
    "                    # Write image to AWS\n",
    "                    with open(filepath, 'rb') as data:\n",
    "                        s3.upload_fileobj(data, filepath)\n",
    "                    # remove comment to stop storing\n",
    "                    # os.remove(filepath)\n",
    "\n",
    "            # for image in prod_dims_images:\n",
    "                \n",
    "            \n",
    "            # Get Product Details Packaging\n",
    "            prod_packaging = bot.driver.find_elements_by_xpath('//*[@id=\"SEC_product-details-packaging\"]//span')\n",
    "            prod_packaging = [item.get_attribute('innerHTML') for item in prod_packaging]\n",
    "            prod_packaging = [x for x in prod_packaging if \"</span>\" not in x]\n",
    "            results_dict['packaging'] = prod_packaging\n",
    "\n",
    "            # Second get all product dimensions\n",
    "            prod_dims_name = bot.driver.find_elements_by_xpath('//*[@class=\"range-revamp-product-dimensions__list-container\"]//dt')\n",
    "            prod_dims_name = [item.get_attribute('innerHTML').split(\":\")[0] for item in prod_dims_name]\n",
    "        \n",
    "            \n",
    "            prod_dims_measure = bot.driver.find_elements_by_xpath('//*[@class=\"range-revamp-product-dimensions__list-container\"]//dd')\n",
    "            prod_dims_measure = [item.get_attribute('innerHTML') for item in prod_dims_measure]\n",
    "            dims = dict(zip(prod_dims_name, prod_dims_measure))\n",
    "            results_dict['prod_dimensions'] = dims\n",
    "\n",
    "\n",
    "            # Cycle through images \n",
    "            images = bot.driver.find_elements_by_xpath('//*[@class=\"range-revamp-media-grid__media-container\"]//img') \n",
    "            images = [i.get_attribute('src') for i in images]\n",
    "\n",
    "            # Product Details\n",
    "            product_details = bot.driver.find_elements_by_xpath('//*[@class=\"range-revamp-product-details__paragraph\"]')\n",
    "            product_details = [paragraph.get_attribute('innerHTML') for paragraph in product_details]\n",
    "            product_details = \" \".join(product_details)\n",
    "            results_dict['prod_details'] = product_details\n",
    "\n",
    "            # Materials\n",
    "            product_details_materials = bot.driver.find_elements_by_xpath('//*[@id=\"SEC_product-details-material-and-care\"]//span')\n",
    "            product_details_materials = [paragraph.get_attribute('innerHTML') for paragraph in product_details_materials]\n",
    "            product_details_materials = \",\".join(product_details_materials)\n",
    "            results_dict['materials'] = product_details_materials\n",
    "\n",
    "            # Sustainability\n",
    "            product_details_sustain = bot.driver.find_elements_by_xpath('//*[@id=\"SEC_product-details-sustainability-and-environment\"]//span')\n",
    "            product_details_sustain = [paragraph.get_attribute('innerHTML') for paragraph in product_details_sustain]\n",
    "            product_details_sustain = \",\".join(product_details_sustain)\n",
    "            results_dict['sustainability'] = product_details_sustain\n",
    "\n",
    "            \n",
    "\n",
    "            # Get reviews\n",
    "            \n",
    "            for image in images:\n",
    "                # Loop through each image and save to disk\n",
    "\n",
    "                for idx, img_url in enumerate(images):\n",
    "\n",
    "                    # Create filename for each with ID and get the file extension\n",
    "                    filename = f'{result}-{idx}'\n",
    "                    file_ext = img_url.split('.')[-1] \n",
    "                    file_ext = file_ext[ 0 : 3 ]\n",
    "                    # Write file locally\n",
    "                    filepath = f'data/{search}/{result}/{filename}.{file_ext}'\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(img_url, filepath)\n",
    "                    except ConnectionResetError:\n",
    "                        print ('Connection Error')\n",
    "                    else:\n",
    "                        img_data = requests.get(img_url).content\n",
    "                        with open(filepath, 'wb') as handler:\n",
    "                            handler.write(img_data)                         \n",
    "                    finally:\n",
    "                        pass\n",
    "                    # Write to cloud\n",
    "                    with open(filepath, 'rb') as data:\n",
    "                        s3.upload_fileobj(data, filepath)\n",
    "                    results_dict['images'].append(filepath)\n",
    "                    # remove comment to remove file locally\n",
    "                    # os.remove(filepath)\n",
    "                    \n",
    "            # Remove duplicate images\n",
    "            results_dict['images'] = [i for j, i in enumerate(results_dict['images']) if i not in results_dict['images'][:j]] \n",
    "            # Wrte dict to local\n",
    "            data_dict[search][i] = results_dict \n",
    "            with open('data_json.txt', 'w') as json_file:\n",
    "                json.dump(data_dict, json_file)            \n",
    "            json.dump_s3(data_dict, \"data_json\")\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                   0\n0  {\"plant pots\": {\"0\": {\"id\": 0, \"prod_name\": \"M...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'read_json'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-73de9bf4a6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m df.read_json({(i,j): f[i][j] \n\u001b[0m\u001b[1;32m     13\u001b[0m                            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                            for j in f[i].keys()},\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'read_json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# with open('data_json.txt', 'r') as file:\n",
    "#     data = file.read().replace('\\n', '')[0:-1]\n",
    "\n",
    "# f = open(\"data_json.txt\", \"r\")\n",
    "\n",
    "df = pd.read_json('data_json.txt')\n",
    "print(df.from_dict(f))\n",
    "\n",
    "df.read_json({(i,j): f[i][j] \n",
    "                           for i in f.keys() \n",
    "                           for j in f[i].keys()},\n",
    "                       orient='index')\n",
    "\n",
    "# print(f)\n",
    "# df = pd.DataFrame(data=f)\n",
    "# print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}